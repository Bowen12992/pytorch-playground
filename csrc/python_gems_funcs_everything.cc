#include <torch/csrc/autograd/utils/wrap_outputs.h>
#include <torch/csrc/utils/pycfunction_helpers.h>
#include <torch/csrc/utils/python_arg_parser.h>
#include <iostream>
#include "kernels/add.h"

// ============================ CODE GEN ============================
/*
These funcs should be generated by a python script with a op-config yaml
Launcher should be generated by a python script
Wrapper for pointwise & reduction maybe codegen
*/

namespace flaggems::py {

void inline add(const at::Tensor& self, const at::Tensor& other, const at::Scalar& alpha) {
  std::cout << "FLAG GEMS ADD" << std::endl;  // use glog change cout into VLOG(1)
  // impl::add_impl(const at::Tensor& self, const at::Tensor& other, const at::Scalar& alpha)
}

inline at::Tensor& add_out(at::Tensor& out,
                           const at::Tensor& self,
                           const at::Tensor& other,
                           const at::Scalar& alpha = 1) {
  std::cout << "FLAG GEMS ADD OUT" << std::endl;  // dito
  // May use Macros to regester a kernel
  flaggems::impl::add_out_impl(out, self, other, alpha);
  return out;
}

static PyObject* gems_PyVariable_add(PyObject* self_, PyObject* args, PyObject* kwargs) {
  HANDLE_TH_ERRORS

  static torch::PythonArgParser parser({
      "add(Tensor input, Tensor other, *, Scalar alpha=1, Tensor out=None)",
  });
  torch::ParsedArgs<4> parsed_args;
  auto r = parser.parse(args, kwargs, parsed_args);

  if (r.isNone(3)) {
    flaggems::py::add(r.tensor(0), r.tensor(1), r.scalar(2));
  } else {
    auto dispatch_add_out = [](at::Tensor out,
                               const at::Tensor& self,
                               const at::Tensor& other,
                               const at::Scalar& alpha) -> at::Tensor {
      pybind11::gil_scoped_release no_gil;
      return flaggems::py::add_out(out, self, other, alpha);
    };
    return torch::autograd::utils::wrap(dispatch_add_out(r.tensor(3), r.tensor(0), r.tensor(1), r.scalar(2)));
  }

  Py_RETURN_NONE;
  END_HANDLE_TH_ERRORS
}

static PyMethodDef gems_functions[] = {
    {  "add", castPyCFunctionWithKeywords(gems_PyVariable_add), METH_VARARGS | METH_KEYWORDS, nullptr},
    {nullptr,                                          nullptr,                            0, nullptr}  // sentinel
};

// Module Def
static struct PyModuleDef module = {
    PyModuleDef_HEAD_INIT,
    /* Module name = */ "flaggems._C",
    /* Docstring = */
    "FlagGems, a tensor library with kernel written by triton-lang and support multi-backend.",
    /* Module size = */ -1,
    /* Function Array size = */ gems_functions};

// Module Init
PyMODINIT_FUNC PyInit__C(void) {
  return PyModule_Create(&module);
}

}  // namespace flaggems::py
